# Оценка качества и настройка порогов

Этот документ помогает превратить метрики модели в стабильные policy-значения для продакшена.

## Базовые метрики

- `Precision`: какая доля положительных алертов действительно была AI UI.
- `Recall`: какую долю реальных AI UI событий удалось поймать.
- `F1`: баланс между precision и recall.
- `Confusion matrix`: где и какие классы путаются.

## Практическая цель для пилота

Для первого rollout приоритет — меньше ложных срабатываний:

- precision >= 0.90 для binary,
- допустимый recall зависит от вашей политики,
- стабильная частота алертов при реальной нагрузке.

## Процесс настройки порогов

1. Начните со значений по умолчанию:
- metadata threshold: `0.55`
- ML threshold: `0.70`
- temporal: `2 из 3`
- cooldown: `20s`

2. Запустите пилот и соберите false positives.
3. Если ложных срабатываний слишком много:
- увеличьте metadata threshold на 0.05,
- увеличьте ML threshold на 0.03-0.05,
- увеличьте cooldown.

4. Если слишком много пропусков:
- немного снизьте пороги,
- добавьте репрезентативные positive-сэмплы,
- улучшите баланс multiclass.

## Рекомендации по временной стабилизации (temporal smoothing)

- `2/3` — сильный базовый вариант.
- `3/5` — строже, но медленнее срабатывает.
- Подберите cooldown так, чтобы подавлять спам и при этом сохранять оперативность.

## Корректировки по конкретным классам

Если один класс шумный (например, `copilot_ui`):

- поднимите порог именно для этого класса в policy (будущее расширение),
- добавьте сложные негативы именно для этого класса,
- анализируйте confusion matrix перед переобучением.

## Операционный мониторинг

Отслеживайте еженедельно:

- алерты на устройство в час,
- процент отклоненных ложных алертов,
- топ причин и stage source (`metadata` vs `onnx`),
- версию модели в алертах.

Используйте это для решения, когда переобучать и переобновлять модель.
